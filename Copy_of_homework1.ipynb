{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "Copy of homework1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tkarani1/ml-hw1/blob/main/Copy_of_homework1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UwU-lXZEFV-4"
      },
      "source": [
        "# Homework 1: Supervised Learning 1: Lab Questions\n",
        "### 25 points total\n",
        "### Version 1.0\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hnRCMdPrSBw8"
      },
      "source": [
        "Aidan Aug (aaug1), Trisha Karani (tkarani1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yS_0juBfFV-5"
      },
      "source": [
        "**Instructions:**\n",
        "This notebook is intended to guide you through creating and exploring your dataset. Please answer all questions in this notebook (you will see <font color='blue'>TODO</font> annotations for where to include your answers). At the beginning of each part, we will bullet the expected deliverables for you to complete. All questions can be answered in 1-4 sentences, unless otherwise noted."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pKB_9fxJFV-5"
      },
      "source": [
        "## Part 1: Defining the Problem and Choosing a Dataset\n",
        "Things to do in this part:\n",
        "1. Answer questions 1-4\n",
        "2. Identify data sources to use in your dataset\n",
        "3. List data sources used in question 5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v-H02HwkFV-6"
      },
      "source": [
        "Your first task is to choose a problem you're interested in. You are free to choose from any domain, but it should be within the **supervised learning** paradigm. In other words, a supervised classifier should be able to generalize from a training sample of $(X,y)$ pairs to predict outcomes on unseen data $x$. We want to use machine learning, so your problem should be difficult to solve using traditional programming algorithms. \n",
        "\n",
        "For simplicity, you will construct data for a binary or multiclass classification problem, where the possible labels are given by a fixed set of choices, or for a regression task (real-valued labels). Do not build a dataset for a structured prediction task.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LgcLquEUFV-7"
      },
      "source": [
        "#### 1) In one or two sentences, what are you interested in predicting given what data? This is your supervised learning problem.\n",
        "\n",
        "You should answer this question before creating your dataset, as it will provide an indication of what to search for."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SBUkGwoQFV-7"
      },
      "source": [
        "**Answer**\n",
        "\n",
        "  The supervised learning problem we hope to solve is whether a patients' data relating to certain body measurements like body fat percentage and/or performance on physical fitness exams can predict their cardiovascular health/fitness."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uM4QYQHuFV-8"
      },
      "source": [
        "#### 2) Is this a well-defined problem? Why or why not? What ambiguities (if any) exist in your problem?\n",
        "\n",
        "Think about what challenges you solved by formulating the problem in this way."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bVz7YeaIFV-9"
      },
      "source": [
        "**Answer**\n",
        "\n",
        "  This is a well defined problem in that we are able to clearly describe the problem at hand, which can be whether an individual has poor or good cardiovascular fitness level. Additionally, cardiovascular health can be clearly defined as maximal oxygen consumption during a cardio-based task.\n",
        "  \n",
        "  Ambiguities may exist in that cardiovascular fitness level can be measured in various ways. Therefore, to accurately measure cardiovascular fitness, a standardized test must be used. Additionally, whether an individual's maximal oxygen consumption corresponds to \"healthy\" or \"not healthy\" can be subjective. This means that a standardized scale must also be used to define the problem."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9jT9VG9nFV-9"
      },
      "source": [
        "#### 3) Does an easy (non-ML) solution exist for the problem? What are existing ways this problem, or a similar problem, is addressed (regardless of difficulty)?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hQEu9DtuFV--"
      },
      "source": [
        "**Answer**\n",
        "\n",
        "  No simple non-ML solution exists for this problem, as the most straightforward solution for measuring cardiorespiratory fitness would be perform a standardized cardio-based exercise across many subjects. However, these exercises can often vary across experiments to measure cardiovascular fitness level, and would normally be completed in a controlled, lab-based environment. This would be relatively difficult, especially to complete by large across a large population."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pzvM5R8eO6G0"
      },
      "source": [
        "#### 4) Why is using machine learning for this problem justified?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DO7DUW_-PCVw"
      },
      "source": [
        "**Answer**\n",
        "\n",
        "  Cardiorespiratory fitness is often used in predicting risk of cardiorespiratory disease in individuals, and also serves as a metric to determine overall physical activity ability. Ethicality in predicting an individual's cardiorespiratory fitness is therefore justified from a medical perspective, and a daily-task perspective. \n",
        "\n",
        "  Furthermore, as there is a clearly defined problem statement, burdonsome current solution, vast amounts of data, and simple method of evaluating our features via linear regression, using machine learning for this problem is justified."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3i70yHkXFV-_"
      },
      "source": [
        "Now, we'll turn to data we can use to actually solve your problem. You may wish to use Section 3.1 of the assignment sheet for inspiration. **Remember, you are expected to *create* a dataset, not use an existing one**.\n",
        "\n",
        "#### 5) List the sources for all data you used when creating your dataset along with (very briefly) what you obtained from it.\n",
        "\n",
        "For example: <br /> Obtained features a,b,c from http://www.domain1.com/example_data. <br /> Obtained labels from http://www.domain2.com/example_labels."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kWYNsEn3FV_A"
      },
      "source": [
        "**Answer**\n",
        "\n",
        "Obtained features a,b,c from :\n",
        "https://wwwn.cdc.gov/Nchs/Nhanes/Search/NnyfsData.aspx?Component=Examination&CycleBeginYear=2012. This hyperlink leads to a webpage with various datasets from the National Health and Nutrition Examination Survey. On this webpage, we used the following datasets:\n",
        "\n",
        "1. Feature a (Average Lower Body Strength) obtained from https://wwwn.cdc.gov/Nchs/Nnyfs/Y_LMX.XPT\n",
        "\n",
        "2. Feature b (Sleep-Awake Ratio) obtained from https://wwwn.cdc.gov/Nchs/Nnyfs/Y_PAXDAY.htm\n",
        "\n",
        "3. Feature c (Normalized Skinfold) obtained from https://wwwn.cdc.gov/Nchs/Nnyfs/Y_BMX.XPT\n",
        "\n",
        "Obtained Labels for each instance from the same website(https://wwwn.cdc.gov/Nchs/Nhanes/Search/NnyfsData.aspx?Component=Examination&CycleBeginYear=2012). \n",
        "\n",
        "1. Link to the actual dataset is: https://wwwn.cdc.gov/Nchs/Nnyfs/Y_CVX.XPT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xudIDiZ0FV_A"
      },
      "source": [
        "## Part 2: What does the data look like?\n",
        "Things to do in this part:\n",
        "1. Answer questions 6-11\n",
        "2. Print a few examples of raw data (if possible) otherwise explain what the raw data looks like.\n",
        "3. Create at least 3 numerical features from your raw data\n",
        "4. Create dataset such that $X\\in\\mathbb{R}^{m\\times n}$ and $y\\in\\mathbb{R}^m$ are both numpy arrays\n",
        "5. Create 1 visual that helps you understand your data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-upcCn1VFV_B"
      },
      "source": [
        "Let's take a look at the various data you've collected. First let's read in the raw data. You may read the data into whatever is most convenient (e.g. a list, a numpy array, a Pandas dataframe, etc.). **At this point your data will be in whatever format you downloaded them in**. For example, if you're working with text data, your data might be strings of words or collection of text documents. If you are working with image data, you might have a collection of images.\n",
        "<br /><br />\n",
        "For those of you new to working with data in Python, we have included examples of how to import the raw data. These are merely suggestions if they work for you. You don't have to use them."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JoUhpBYFFV_B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba18f60a-3f61-43c2-faa8-ff7af3f361ac"
      },
      "source": [
        "# # Suppose you have a directory called documents that contains Wikipedia articles, you can process these as follows:\n",
        "# # Cleaning the data (e.g. removing stop words) is not required.\n",
        "# import os\n",
        "# from collections import defaultdict\n",
        "\n",
        "# files = [f for f in os.listdir('documents') if os.path.isfile(os.path.join('documents', f))\n",
        "# X = defaultdict(list)\n",
        "# for i, file in enumerate(files[:len(files)], start=1):\n",
        "#     with open(os.path.join('documents', file)) as f:\n",
        "#         X['doc_' + str(i)] = f.readlines()\n",
        "# # X is a dictinary that maps doc_id to text.\n",
        "\n",
        "# # Suppose you have labels that are stored in a CSV file:\n",
        "# import pandas as pd\n",
        "\n",
        "# y = pd.read_csv('labels.csv')\n",
        "# # y is a Pandas dataframe that contains each label.\n",
        "\n",
        "# # Suppose you have a directory called images that contains pictures of cats, you can process them as follows:\n",
        "# from PIL import Image\n",
        "\n",
        "# images = [f for f in os.listdir('images') if os.path.isfile(os.path.join('images', f))\n",
        "# X = [Image.open(image) for image in images]\n",
        "# # X is a list of PIL Image objects\n",
        "\n",
        "#######################################################\n",
        "# TODO: Read in your raw data\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "# Our data is stored in SAS files in Github. \n",
        "# We simply have to use the raw file link and import it directly\n",
        "if (os.path.isdir('ml-hw1') == False):\n",
        "  !git clone https://github.com/tkarani1/ml-hw1.git\n",
        "\n",
        "# First, read in the raw data\n",
        "body_data = pd.read_sas(\"/content/ml-hw1/Y_BMX.XPT\")\n",
        "plank_data = pd.read_sas(\"/content/ml-hw1/Y_PLX.XPT\")\n",
        "cardio_data = pd.read_sas(\"/content/ml-hw1/Y_CVX.XPT\")\n",
        "cardio_end_data = pd.read_sas(\"/content/ml-hw1/Y_CEX.XPT\")\n",
        "pullup_data = pd.read_sas(\"/content/ml-hw1/Y_MPX.XPT\")\n",
        "lowerbody_data = pd.read_sas(\"/content/ml-hw1/Y_LMX.XPT\")\n",
        "physact_data = pd.read_sas(\"/content/ml-hw1/Y_PAXDAY.XPT\")\n",
        "\n",
        "# Next, process the data to create a table of (raw) features\n",
        "leg_force = lowerbody_data.filter(['SEQN','LBLEXT1', 'LBLEXT2', 'LBLEXT3', 'LBREXT1', 'LBREXT2', 'LBREXT3'], axis=1)\n",
        "cardio_level = cardio_data.filter(['SEQN','CVDFITL2'], axis=1)\n",
        "sleep_awake = physact_data.filter(['SEQN','PAXSWMD', 'PAXWWMD'], axis=1)\n",
        "skinfold = body_data.filter(['SEQN', 'BMXCALFF', 'BMXSUB', 'BMXTRI'], axis=1)\n",
        "\n",
        "# todo: delete the following b/c unused\n",
        "#max_pullups = lowerbody_data.filter(['SEQN','MPXPULL'], axis=1)\n",
        "#max_plank = plank_data.filter(['SEQN','MPXPLANK'], axis=1)\n",
        "#bmi = body_data.filter(['SEQN','BMXBMI'], axis=1)\n",
        "\n",
        "X = pd.concat([leg_force, sleep_awake, skinfold], axis = 1)\n",
        "y = cardio_level\n",
        "\n",
        "#######################################################"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pandas/io/sas/sas_xport.py:475: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[x] = v\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OTyyXMhtFV_F"
      },
      "source": [
        "Now, let's print a few examples. Depending on your data format, you may have to \n",
        "write this yourself. We have provided some examples below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EygmSPFnFV_F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "61cffe4e-b501-48e1-bcf8-e8b20241de26"
      },
      "source": [
        "# # If your data is stored in an array:\n",
        "# print('X:', X[:5])\n",
        "# print('y:', y[:5])\n",
        "\n",
        "# # If your data consists of image files:\n",
        "# from PIL import Image\n",
        "\n",
        "# for i in range(5):\n",
        "#     print('image:')\n",
        "#     img = X[i]\n",
        "#     img.show()\n",
        "#     print('label:', y[i])\n",
        "\n",
        "#######################################################\n",
        "# TODO: print out what a few examples of your raw data.\n",
        "\n",
        "print(X.head())\n",
        "print(y.head())\n",
        "#######################################################"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      SEQN  LBLEXT1  LBLEXT2  LBLEXT3  ...     SEQN  BMXCALFF  BMXSUB  BMXTRI\n",
            "0  71917.0      NaN      NaN      NaN  ...  71917.0       NaN     NaN     NaN\n",
            "1  71918.0     61.9     60.5     64.8  ...  71918.0      22.0    17.4    19.9\n",
            "2  71919.0     65.8     68.1     74.8  ...  71919.0      18.4     9.8    15.0\n",
            "3  71920.0     83.2    108.9    103.2  ...  71920.0       NaN    22.8    20.6\n",
            "4  71922.0    102.6    108.6    105.5  ...  71921.0       8.4     5.7     8.6\n",
            "\n",
            "[5 rows x 14 columns]\n",
            "      SEQN  CVDFITL2\n",
            "0  71917.0       NaN\n",
            "1  71919.0       1.0\n",
            "2  71920.0       3.0\n",
            "3  71922.0       3.0\n",
            "4  71923.0       1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_O9OGkeHOW0V"
      },
      "source": [
        "#### (Optional) If your raw data format can't be displayed in a Jupyter notebook (e.g. video or audio files), you may skip the above step. You should still look at the raw data in whatever way possibly, but instead just describe what the raw data is that you look at."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WeRwNo2-O3XQ"
      },
      "source": [
        "<font color='blue'>\n",
        "    TODO: replace this cell with your answer. Leave blank if not applicable.\n",
        "</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6LrYreKhFV_I"
      },
      "source": [
        "#### 6) What information is contained in each example (row) in $X$? These are your raw data features."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q9_MNK-1FV_I"
      },
      "source": [
        "<font color='blue'>\n",
        "    TODO: replace this cell with your answer\n",
        "</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nnloVU9iFV_J"
      },
      "source": [
        "If your data is not numerical, this will be difficult for an algorithm to learn directly. So, now that you've seen what the raw data looks like, you will start extracting *numerical* features from the raw data.\n",
        "<br /><br />\n",
        "We obtain features through a process called **feature engineering**. Features may be derived from the existing raw data or may come from other data sources that can be associated with each example. This is a challenging task that often requires domain knowledge about the problem you are trying to solve. \n",
        "<br /><br />\n",
        "While very important in dataset creation, feature engineering is not the focus of this assignment. You will need some features for the other steps, but these can be very simple and don't need to rely on domain knowledge.\n",
        "<br /><br />\n",
        "**You will need to add at least 3 features to your dataset**. If your data is Wikipedia documents, possible features could be number of sentences, word count, the words that appear in the article, number of document revisions, number of contributing authors, number of references, etc. Notice that some of these features could be derived from the raw data (i.e. the words) while others may need to be downloaded separately (i.e. page metadata). If your data are cat images, your features could be focus measure (i.e. blurriness/sharpness) using OpenCV Variance of Laplacian, whether image is grayscale, number of pixels, the pixel color values, etc.\n",
        "<br /><br />\n",
        "You are free to obtain features in any way you like as long as you can justify why the features your propose should help solve the problem you've defined.\n",
        "<br /><br />\n",
        "We'll provide some examples of what we're looking for. We are not expecting anything fancy for this step."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qf0HOYw8FV_K"
      },
      "source": [
        "# # If you're using text data stored in a dictionary (like example above):\n",
        "# # Suppose each document is a string that contains a period\n",
        "# # and are trying to predict end of sentences (EOS),\n",
        "# import re\n",
        "# import pandas as pd\n",
        "# from collections import defaultdict\n",
        "\n",
        "# # Convert X from doc_id -> text to doc_id -> {sentence, features}\n",
        "# X = {k:{'sentence': v, 'features': None} for k,v in X.items()}\n",
        "\n",
        "# # suppose you downloaded these external data: common abbreviations, titles (e.g. mr, ms, dr), month abbreviations (e.g. sept, oct)\n",
        "# abbrevs = pd.read_csv('common_abbrevs.csv')\n",
        "# titles = pd.read_csv('titles.csv')\n",
        "# months = pd.read_csv('month_abbrevs.csv')\n",
        "\n",
        "# # for the purpose of this example, assume all documents have len > 3\n",
        "# features = defaultdict(int)\n",
        "# for doc_id, doc in X.items():\n",
        "#     idx = re.find('.')\n",
        "#     one_before = doc['sentence'][idx - 1] if idx > 0 else None\n",
        "#     one_after = doc['sentence'][idx + 1] if idx < len(doc['sentence']) - 1 else None\n",
        "#     features['is_abbrev'] = 1 if one_before and one_before in abbrevs else 0\n",
        "#     features['is_title'] = 1 if one_before and one_before in titles else 0\n",
        "#     features['is_month'] = 1 if one_before and one_before in months else 0\n",
        "#     features['is_decimal'] = 1 if one_before and one_after in one_before.isdigit() and one_after.isdigit() else 0\n",
        "#     features['other_punc'] = 1 if any((p in '?!.') for c in doc['sentence'][idx:]) else 0\n",
        "#     features['period_loc'] = idx\n",
        "#     X[doc_id]['features'] = features\n",
        "# # In just a few lines of Python, we created 6 features!\n",
        "\n",
        "#######################################################\n",
        "# TODO: compute features for each example\n",
        "\n",
        "# Create a feature relating to total lower-body strength\n",
        "leg_force = leg_force.dropna()\n",
        "leg_force['AVG_LEG_FORCE'] = (leg_force['LBLEXT1'] + leg_force['LBLEXT2'] + leg_force['LBLEXT3'] + leg_force['LBREXT1'] + leg_force['LBREXT2'] + leg_force['LBREXT3'])/6 #find mean leg force from 3 tests on left and right legs\n",
        "leg_force['AVG_LEG_FORCE_NORM'] = leg_force['AVG_LEG_FORCE'] / (leg_force['AVG_LEG_FORCE']).max()\n",
        "leg_force_feat = leg_force.filter(['SEQN','AVG_LEG_FORCE_NORM'], axis=1)\n",
        "\n",
        "# Create a feature relating sleep to awake time\n",
        "sleep_awake = sleep_awake.dropna()\n",
        "sleep_awake = sleep_awake[sleep_awake['PAXSWMD'] >= 120]\n",
        "sleep_awake = sleep_awake[sleep_awake['PAXWWMD'] >= 120]\n",
        "sleep_awake = sleep_awake.groupby(['SEQN']).mean()\n",
        "sleep_awake['SLP_AWK_RATIO'] = sleep_awake['PAXSWMD'] / sleep_awake['PAXWWMD']\n",
        "sleep_awake_feat = sleep_awake.filter(['SEQN','SLP_AWK_RATIO'], axis=1)\n",
        "sleep_awake_feat\n",
        "\n",
        "# Create a feature relating to total subcutaneous body fat\n",
        "skinfold = skinfold.dropna()\n",
        "skinfold['SKINFOLD_SUM'] = skinfold['BMXCALFF'] + skinfold['BMXSUB'] + skinfold['BMXTRI']\n",
        "skinfold['SKINFOLD_SUM_NORM'] = skinfold['SKINFOLD_SUM'] / (skinfold['SKINFOLD_SUM']).max()\n",
        "skinfold_feat = skinfold.filter(['SEQN','SKINFOLD_SUM_NORM'], axis=1)\n",
        "\n",
        "# Process the label to be a binary label\n",
        "cardio_level = cardio_level.dropna()\n",
        "cardio_level.loc[cardio_level['CVDFITL2'] == 1, 'CVDFITL2'] = 0\n",
        "cardio_level.loc[cardio_level['CVDFITL2'] == 2, 'CVDFITL2'] = 0\n",
        "cardio_level.loc[cardio_level['CVDFITL2'] == 3, 'CVDFITL2'] = 1\n",
        "cardio_level.loc[cardio_level['CVDFITL2'] == 4, 'CVDFITL2'] = 1\n",
        "cardio_level_processed = cardio_level.copy();\n",
        "cardio_level_processed = cardio_level.rename(columns={'CVDFITL2' : 'CARDIO_LEVEL'})\n",
        "\n",
        "# Create a dataframe with all features and labels corresponding to each individual participant\n",
        "leg_force_sleep_awake = pd.merge(leg_force_feat, sleep_awake_feat, on='SEQN', how='inner')\n",
        "skinfold_cardio_level = pd.merge(skinfold_feat, cardio_level_processed, on='SEQN', how='inner')\n",
        "features_labels = pd.merge(leg_force_sleep_awake, skinfold_cardio_level, on='SEQN', how='inner')\n",
        "features_labels = features_labels.dropna()\n",
        "\n",
        "X_processed = features_labels.filter(['AVG_LEG_FORCE_NORM','SLP_AWK_RATIO', 'SKINFOLD_SUM_NORM'], axis=1)\n",
        "y_processed = features_labels.filter(['CARDIO_LEVEL'])\n",
        "#######################################################"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0kvDukQY_MOT"
      },
      "source": [
        "#### 7) Describe the features in your dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ccp6_xtTFV_J"
      },
      "source": [
        "**Answer**\n",
        "\n",
        "The engineered features we added to our dataset were average leg force generated across 3 experiments and both legs, the ratio of sleep time to awake time, and an averaged amount of skinfold.\n",
        "\n",
        "1. Average leg force Generated: The original data we took from NNYFS dataset on lower body strength included three experiments measuring left leg extension muscle strength, and three experiments measuring the right. We averaged across all these features to generate a feature measuring total lower body strength and then normalized the values. \n",
        "\n",
        "2. Ratio of Sleep to Awake Time: The original data we took from the NNYFS website had a physical activity monitor (PAM) dataset, where participants wore a PAM accelerometer device to measure total physical activity. One of the features measured total awake time, and another sleep time. However, much of the data was lost as it was either missing or did not directly correspond to either state. By comparing these two values, we were able to determine a ratio for total sleep to total awake time.\n",
        "\n",
        "3. Average amount of Skinfold: The original data on body measurements had 3 features measuring amount of skinfold on each participant. As skinfold directly relates to subcutaneous body fat, we summed and normalized these values to determine a proxy for total amount of body fat in each participant."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TpHvVRWLFV_N"
      },
      "source": [
        "Next, let's focus on what you're trying to predict. First, let's see what the potential outcomes look like."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_sffSMwfFV_N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d6b9d04-e729-449b-afe7-e412937fd8a6"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "np.unique(y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 1.])"
            ]
          },
          "metadata": {},
          "execution_count": 179
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B4K9ymaUFV_Q"
      },
      "source": [
        "#### 8) Is your dataset suitable for a regression or classification task? Explain."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LGM97EwNFV_R"
      },
      "source": [
        "**Answer**\n",
        "\n",
        "This dataset is suitible for a classification task. The outcome predicted is not continuous, and instead simply tries to predict the correct label (fit or unfit in terms of cardiorespiratory health). Whether or not they are \"close\" to fitness or not does not matter. Instead, only classification matters to relate whether the invidiual should or should not seek additional aid to improve their cardiorespiratory health."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZftGGzDOFV_R"
      },
      "source": [
        "Now, we'll standardize our data as follows. The data matrix $X$ should be a numpy 2d array in $\\mathbb{R}^{m\\times n}$. The labels should be a numpy 1d array in $\\mathbb{R}^m$. $m$ is the number of examples and $n$ is the number of features. **You will be training your supervised classifer on the features, which might not include all (or any) of the raw data**. This is a decision you will make when creating your dataset.\n",
        "<br /><br />\n",
        "Note: this is the format we're looking for your data to be in when you submit your dataset (i.e. $X\\in\\mathbb{R}^{m\\times n}$ and $y\\in\\mathbb{R}^m$ and are both numpy arrays)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wr0fOeO4FV_S"
      },
      "source": [
        "# # Now, using your numerical features from the previous step, you can construct the dataset.\n",
        "# # Depending on what your raw data was (i.e. if any field was numerical), you may include this in the final dataset\n",
        "# # or you may just use the features you created. \n",
        "\n",
        "# # Using the dictionary from above (doc_id -> {sentence, features}) the dataset can be constructed\n",
        "# import numpy as np\n",
        "\n",
        "# X = np.array([np.array(doc.features.values()) for doc in X.values()])\n",
        "# y = np.array(y) # assume y was a list of binary labels previously\n",
        "\n",
        "#######################################################\n",
        "# TODO: Convert X and y to numpy arrays with appropriate dimensions\n",
        "import numpy as np\n",
        "X = X.to_numpy()\n",
        "y = np.array(y)\n",
        "\n",
        "#######################################################"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "otLeZuuXFV_V"
      },
      "source": [
        "If you have a classification dataset, let's look at class balance. This tells us how many examples we have for each label."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mpg27X_XFV_V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fcfba80d-1dc3-4964-946c-21a3c2e3043c"
      },
      "source": [
        "for i in np.unique(y):\n",
        "    print(f'{len(y[y==i])} examples of class {i}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "204 examples of class 0.0\n",
            "134 examples of class 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o_ecYJ4xFV_Y"
      },
      "source": [
        "#### 9) Classification: Is your dataset balanced or imbalanced?\n",
        "\n",
        "\n",
        "Regression: How are your labels distributed? Normal distrbution? Uniform within a range? etc."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gin5wkqFFV_Y"
      },
      "source": [
        "The dataset is imbalanced, as there are an unequal number of examples where participants were unfit (204) compared to those who were fit (134). This comes to be a ratio of 102:67, with 60% total participants labeled as unfit and 40% total participants labeled as fit."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NeSyM-x6FV_Z"
      },
      "source": [
        "Let's compute some statistics for the dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0B5593CnFV_a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2785aa02-22ec-4654-a97b-6ffec178366a"
      },
      "source": [
        "#######################################################\n",
        "print(f'Number of examples: {X.shape[0]}')\n",
        "print(f'Number of features per example: {X.shape[1]}')\n",
        "# there are many more that are relevant to the specific domain your data is in.\n",
        "# TODO: if applicable, please include any additional dataset statistics here\n",
        "#######################################################"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of examples: 338\n",
            "Number of features per example: 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NXUdUevoORfr"
      },
      "source": [
        "#### 10) Do you have lots of high quality data? Explain limitations (if any) that exist in terms of data quantity and quality."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WmQGjl9JOiOk"
      },
      "source": [
        "**Answer**\n",
        "\n",
        "The primary limitation of this data is quantity: there are only several hundred, specifically 338, instances we can train (and test) on. This is because the data we are using is taken from physical examinations of participants, which is often only performed in a controlled/at-home environment. Based on ethical concerns and population limitations, this makes the data pool rather small.\n",
        "\n",
        "Another limitation is that many participants had NaN values for certain physical measurements, and some participants did not complete the entirety of the physical examinations. We had to remove the instances for which data was missing, which also lead to a loss in quantity.\n",
        "\n",
        "In terms of the actual quantity of the data, the majority of the features from the NNYFS datasets were measured in a controlled environment. This standardization of physical examination procedures ensured higher quality of the data. One exception is the sleep-awake time data, where participants wore a physical activity monitor in an at-home setting. This lead to both loss of data, and non-standardized measurements that could affect the calculated sleep-awake time features."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZGdroDhAUoiU"
      },
      "source": [
        "Data visualizations help us understand our data and draw insights. Just like there is no single ML algorithm that applies to every problem, there isn't a visualization that works for every dataset.\n",
        "<br /> <br />\n",
        "Instead, you will produce some visuals that you think tell an interesting story about your data. We will provide some suggestions, which you can use for inspiration. \n",
        "<br /> <br />\n",
        "\n",
        "Types of information you may wish to capture (this is by no means comprehensive):\n",
        "*   Missingness of data (consider using heat maps, scatter plots)\n",
        "*   Correlation of features (consider using a correlation matrix)\n",
        "*   Distribution of data (consider using historgrams, violin plots)\n",
        "*   Linear separability, if you have binary classification\n",
        "<br /> <br />\n",
        "\n",
        "Check out these visualization galleries for further inspiration and example code:\n",
        "*   [Seaborn](https://seaborn.pydata.org/examples/index.html)\n",
        "*   [Plotly](https://plotly.com/python/)\n",
        "*   [Python Graph Gallery](https://python-graph-gallery.com/)\n",
        "\n",
        "You should create **at least 1 visualization** for your dataset and explain what you learned about your data from it. Below is an example heatmap showing correlation of features from the sklearn iris dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OR77uBw_gI72",
        "outputId": "fa56034c-0aa2-4f94-c25c-04c00c63594e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        }
      },
      "source": [
        "from sklearn import datasets\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "iris = datasets.load_iris()\n",
        "df = pd.DataFrame(data= np.c_[iris['data'], iris['target']],\n",
        "                     columns= iris['feature_names'] + ['target'])\n",
        "sns.heatmap(df.corr(), \n",
        "            xticklabels=df.corr().columns.values,\n",
        "            yticklabels=df.corr().columns.values)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LSbCeDaDFV_h"
      },
      "source": [
        "#######################################################\n",
        "# TODO: Visualize the dataset\n",
        "\n",
        "#######################################################"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gb2f_TdIFV_j"
      },
      "source": [
        "#### 11) What insights do you gain from this visualization about your dataset?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ma30TfvrFV_k"
      },
      "source": [
        "<font color='blue'>\n",
        "    TODO: replace this cell with your answer\n",
        "</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ByuJGGbJFV_k"
      },
      "source": [
        "## Part 3: Using your dataset\n",
        "\n",
        "Things to do in this part:\n",
        "1. Answer questions 12-13\n",
        "2. Perform a train-test split\n",
        "3. Train simple supervised learning algorithm on dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "abr91MAtFV_k"
      },
      "source": [
        "Now that you have created your dataset and explored some of its properties, you will use a supervised classifier to predict the outcome you definined in the problem statement. To evaluate how well this classifier predicts the outcomes, you will need to set some data aside for testing. First, you'll use sklearn to split the data into train and test sets, with 25% of the data reserved for testing."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pvsUJRE7FV_l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8feedcda-ca59-46a0-d422-0749333208a7"
      },
      "source": [
        "from sklearn.model_selection import train_test_split \n",
        "\n",
        "# Train Test Split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=0)\n",
        "print(f'Training examples: {X_train.shape[0]}\\nTesting examples{ {X_test.shape[0]}}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training examples: 253\n",
            "Testing examples{85}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0CAu1ruKa-9C"
      },
      "source": [
        "Now, we'll save your train and test sets. Together, these four files will make up the dataset you submit on Gradescope. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QANcYHlobNNb"
      },
      "source": [
        "import numpy as np \n",
        "\n",
        "np.savetxt(\"X_train.csv\", X_train, delimiter=\",\")\n",
        "np.savetxt(\"X_test.csv\", X_test, delimiter=\",\")\n",
        "np.savetxt(\"y_train.csv\", y_train, delimiter=\",\")\n",
        "np.savetxt(\"y_test.csv\", y_test, delimiter=\",\")\n",
        "\n",
        "# zip together all components of your dataset\n",
        "!zip homework1_dataset.zip X_train.csv X_test.csv y_train.csv y_test.csv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cS9ISdLyFV_o"
      },
      "source": [
        "Now, let's train some classifiers or regression models. You are encouraged to try out multiple different algorithms, but only one is required. You are also encouraged to use popular packages such as [sklearn](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.linear_model); you are not expected to implement any of these algorithms yourself. We have included sklearn's Logistic Regression and Linear Regression algorithms below as examples.\n",
        "<br /><br />\n",
        "Consider trying the following algorithms:\n",
        "<br />\n",
        "Classification: SVM, Decision Tree, Random Forest\n",
        "<br />\n",
        "Regression: Lasso, ridge regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uRlJ86C8FV_o"
      },
      "source": [
        "# # If you have a classification problem, here is how to train a Logistic Regression classifier\n",
        "\n",
        "# from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# clf = LogisticRegression(random_state=0).fit(X_train, y_train)\n",
        "# y_hat = clf.predict(X_test)\n",
        "# accuracy = clf.score(X_test, y_test)\n",
        "# print(f'model accuracy is {accuracy}')\n",
        "\n",
        "# # If you have a regression problem, here is how to train a Linear Regression classifier\n",
        "\n",
        "# from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# reg = LinearRegression().fit(X_train, y_train)\n",
        "# y_hat = reg.predict(X_test)\n",
        "# r_squared = reg.score(X_test, y_test)\n",
        "# print(f'Goodness of fit given by coefficient of determination is {r_squared}')\n",
        "\n",
        "#######################################################\n",
        "# TODO: Train at least one simple supervised learning algorithm on your dataset\n",
        "\n",
        "#######################################################"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "clf = LogisticRegression(random_state=0).fit(X_train, y_train)\n",
        "y_hat = clf.predict(X_test)\n",
        "accuracy = clf.score(X_test, y_test)\n",
        "print(f'model accuracy is {accuracy}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6F3GwuzvMadX",
        "outputId": "10868c64-6455-430d-eba8-94dd7afd00df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model accuracy is 0.6352941176470588\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#SVM\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.datasets import make_classification\n",
        "clf = make_pipeline(StandardScaler(),LinearSVC(random_state=0, tol=1e-5, max_iter=10000))\n",
        "clf.fit(X_train, y_train)\n",
        "y_hat = clf.predict(X_test)\n",
        "accuracy = clf.score(X_test, y_test)\n",
        "print(f'model accuracy is {accuracy}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kVLNmZJnM0Ij",
        "outputId": "5828ff05-92df-47e4-dbac-f230650507c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model accuracy is 0.6470588235294118\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Decision Tree\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "clf = DecisionTreeClassifier(random_state=0)\n",
        "clf.fit(X_train, y_train)\n",
        "y_hat = clf.predict(X_test)\n",
        "accuracy = clf.score(X_test, y_test)\n",
        "print(f'model accuracy is {accuracy}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TGF_OBq1PvTY",
        "outputId": "73f80a9f-1caa-4c08-d95f-54f127f90d17"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model accuracy is 0.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Random Forest\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.datasets import make_classification\n",
        "clf = RandomForestClassifier(random_state=0)\n",
        "clf.fit(X_train, y_train)\n",
        "y_hat = clf.predict(X_test)\n",
        "accuracy = clf.score(X_test, y_test)\n",
        "print(f'model accuracy is {accuracy}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M5T9eay9TL_E",
        "outputId": "15abf954-b7e9-46a5-b17b-4aa7384d4811"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model accuracy is 0.611764705882353\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  \"\"\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "geo8Kz4tOtLy"
      },
      "source": [
        "#### 12) How can you meaningfully evaluate results?  How was the performance of your model: did it meee?\n",
        "*Note:* if you trained more than one model above, you only need to answer this question for one of them."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b3nzN7MtOz45"
      },
      "source": [
        "<font color='blue'>\n",
        "    TODO: replace this cell with your answer\n",
        "</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fPIbEyVOPWsy"
      },
      "source": [
        "#### 13) In creating your dataset, what discussions did you have about the ethical implications of what you were collecting? Are there any potential issues with fairness?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gc-5zTUHPyyg"
      },
      "source": [
        "<font color='blue'>\n",
        "    TODO: replace this cell with your answer\n",
        "</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ll5FhwgKx4K6"
      },
      "source": [
        "## Submit\n",
        "Great work! You're all done.\n",
        "\n",
        "Make sure to submit this Python notebook (as a PDF) and the dataset you created as a zip file. See the homework writeup for directions."
      ]
    }
  ]
}